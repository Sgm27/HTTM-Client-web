from transformers import VitsModel, AutoTokenizer
import torch
import numpy as np
from scipy.io.wavfile import write

# Load model + tokenizer
model = VitsModel.from_pretrained("facebook/mms-tts-vie").to("cuda")
tokenizer = AutoTokenizer.from_pretrained("facebook/mms-tts-vie")

# ğŸ“Œ Má»™t vÄƒn báº£n dÃ i, khÃ´ng chia nhá»
text = (
    "TrÃ­ tuá»‡ nhÃ¢n táº¡o, hay cÃ²n gá»i lÃ  AI, Ä‘ang ngÃ y cÃ ng trá»Ÿ thÃ nh má»™t pháº§n khÃ´ng thá»ƒ thiáº¿u "
    "trong xÃ£ há»™i hiá»‡n Ä‘áº¡i. NÃ³ xuáº¥t hiá»‡n trong Ä‘iá»‡n thoáº¡i thÃ´ng minh, trong cÃ¡c á»©ng dá»¥ng tÃ¬m kiáº¿m, "
    "trong dá»‹ch vá»¥ chÄƒm sÃ³c khÃ¡ch hÃ ng vÃ  tháº­m chÃ­ trong cáº£ lÄ©nh vá»±c nghá»‡ thuáº­t sÃ¡ng táº¡o. "
    "AI giÃºp cÃ¡c bÃ¡c sÄ© cháº©n Ä‘oÃ¡n bá»‡nh nhanh hÆ¡n, giÃºp ká»¹ sÆ° tá»‘i Æ°u hÃ³a sáº£n xuáº¥t, "
    "giÃºp giÃ¡o viÃªn cÃ¡ nhÃ¢n hÃ³a chÆ°Æ¡ng trÃ¬nh há»c cho tá»«ng há»c sinh. "
    "Trong ngÃ nh giao thÃ´ng, AI há»— trá»£ phÃ¡t triá»ƒn xe tá»± lÃ¡i, giáº£m thiá»ƒu tai náº¡n vÃ  táº¯c Ä‘Æ°á»ng. "
    "Trong tÃ i chÃ­nh, AI Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¡t hiá»‡n gian láº­n vÃ  phÃ¢n tÃ­ch rá»§i ro Ä‘áº§u tÆ°. "
    "AI cÅ©ng Ä‘ang má»Ÿ ra nhá»¯ng kháº£ nÄƒng má»›i trong khoa há»c, nhÆ° mÃ´ phá»ng quÃ¡ trÃ¬nh khÃ¡m phÃ¡ vÅ© trá»¥, "
    "nghiÃªn cá»©u khÃ­ háº­u toÃ n cáº§u vÃ  phÃ¡t triá»ƒn thuá»‘c má»›i. "
    "Tuy nhiÃªn, AI cÅ©ng Ä‘áº·t ra nhiá»u thÃ¡ch thá»©c, bao gá»“m váº¥n Ä‘á» quyá»n riÃªng tÆ°, an ninh dá»¯ liá»‡u "
    "vÃ  sá»± thay Ä‘á»•i trong thá»‹ trÆ°á»ng lao Ä‘á»™ng. "
    "ChÃ­nh vÃ¬ váº­y, viá»‡c phÃ¡t triá»ƒn AI cáº§n Ä‘i kÃ¨m vá»›i cÃ¡c chÃ­nh sÃ¡ch vÃ  quy Ä‘á»‹nh phÃ¹ há»£p "
    "Ä‘á»ƒ Ä‘áº£m báº£o cÃ´ng nghá»‡ nÃ y phá»¥c vá»¥ lá»£i Ã­ch cá»§a toÃ n nhÃ¢n loáº¡i. "
    "Vá»›i tá»‘c Ä‘á»™ phÃ¡t triá»ƒn nhanh chÃ³ng, AI há»©a háº¹n sáº½ tiáº¿p tá»¥c thay Ä‘á»•i cÄƒn báº£n cÃ¡ch con ngÆ°á»i "
    "sá»‘ng, lÃ m viá»‡c vÃ  tÆ° duy trong tháº¿ ká»· 21."
)

# Encode nguyÃªn vÄƒn báº£n
inputs = tokenizer(text, return_tensors="pt").to("cuda")

# Run inference
with torch.no_grad():
    output = model(**inputs).waveform

waveform = output.cpu().numpy().squeeze()  # shape (samples,)
sr = model.config.sampling_rate

# HÃ m táº¡o chunk tá»« waveform
def audio_chunk_generator(waveform, chunk_size=16000*3):  
    """
    chunk_size: sá»‘ samples má»—i chunk
    VD: sr*3 = 3 giÃ¢y 1 chunk (náº¿u sr=16kHz thÃ¬ ~48000 máº«u)
    """
    for i in range(0, len(waveform), chunk_size):
        yield waveform[i:i + chunk_size]

# LÆ°u tá»«ng chunk thÃ nh file audio riÃªng
for idx, chunk in enumerate(audio_chunk_generator(waveform, chunk_size=sr*3), start=1):
    filename = f"audio_chunk_{idx}.wav"
    write(filename, sr, chunk)
    print(f"Saved {filename}, length: {len(chunk)/sr:.2f} sec")
